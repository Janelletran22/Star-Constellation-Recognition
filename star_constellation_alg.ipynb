{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# constellation detection system\n",
    "fully functioning training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated YAML configuration at stars_constellations_dataset/constellation_data.yaml\n",
      "Training YOLOv8s model...\n",
      "New https://pypi.org/project/ultralytics/8.3.114 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.112  Python-3.11.5 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=stars_constellations_dataset/constellation_data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=constellation_detector12, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0005, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\constellation_detector12\n",
      "Overriding model.yaml nc=80 with nc=16\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2122240  ultralytics.nn.modules.head.Detect           [16, [128, 256, 512]]         \n",
      "Model summary: 129 layers, 11,141,792 parameters, 11,141,776 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 303.491.9 MB/s, size: 35.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Dell\\Downloads\\Star Constellation\\stars_constellations_dataset\\labels\\train.cache... 1530 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1530/1530 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 237.530.6 MB/s, size: 37.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Dell\\Downloads\\Star Constellation\\stars_constellations_dataset\\labels\\val.cache... 146 images, 0 backgrounds, 0 corrupt: 100%|██████████| 146/146 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\constellation_detector12\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0005, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\constellation_detector12\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      7.24G       2.42      3.787      2.002         37        640: 100%|██████████| 96/96 [00:52<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.544      0.291      0.373      0.157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      7.24G      1.863      1.378      1.567         41        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.735      0.733      0.809      0.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      7.28G      1.745      1.112      1.476         38        640: 100%|██████████| 96/96 [00:50<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.771      0.858      0.872      0.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      7.24G      1.683     0.9896      1.448         28        640: 100%|██████████| 96/96 [00:54<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.869      0.793      0.873      0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      7.24G      1.585      0.884      1.373         23        640: 100%|██████████| 96/96 [01:05<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561       0.83      0.896      0.916      0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      7.28G      1.546       0.82      1.357         41        640: 100%|██████████| 96/96 [00:58<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.865      0.897      0.895      0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      7.28G      1.511     0.7726       1.34         34        640: 100%|██████████| 96/96 [00:59<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.849      0.924      0.926      0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      7.28G      1.458       0.72      1.311         43        640: 100%|██████████| 96/96 [00:54<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.861      0.917      0.926      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      7.28G      1.408     0.6728      1.271         40        640: 100%|██████████| 96/96 [01:04<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.876       0.93      0.943       0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      7.28G      1.386     0.6511      1.265         33        640: 100%|██████████| 96/96 [00:53<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.886      0.923      0.943      0.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.174 hours.\n",
      "Optimizer stripped from runs\\detect\\constellation_detector12\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from runs\\detect\\constellation_detector12\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating runs\\detect\\constellation_detector12\\weights\\best.pt...\n",
      "Ultralytics 8.3.112  Python-3.11.5 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "Model summary (fused): 72 layers, 11,131,776 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.875      0.931      0.943      0.551\n",
      "                Aquila         28         28      0.945          1      0.994      0.642\n",
      "                Bootes         34         34      0.925          1      0.995      0.644\n",
      "           Canis Major         29         29      0.939          1      0.995      0.623\n",
      "           Canis Minor         35         35      0.887      0.895      0.962      0.383\n",
      "            Cassiopeia         49         49       0.86          1      0.976      0.561\n",
      "                Cygnus         35         35       0.73      0.971      0.966      0.696\n",
      "                Gemini         36         36      0.994      0.944      0.985      0.611\n",
      "                   Leo         30         30      0.868          1      0.987      0.642\n",
      "                  Lyra         41         41      0.759      0.976      0.975      0.462\n",
      "                  Moon         40         40      0.741        0.8      0.772      0.319\n",
      "                 Orion         32         32      0.981          1      0.995      0.687\n",
      "              Pleiades         51         51      0.732       0.49      0.563      0.165\n",
      "           Sagittarius         18         18      0.896      0.962       0.99      0.446\n",
      "                Taurus         27         27      0.915      0.926      0.973       0.63\n",
      "            Ursa Major         33         33      0.969      0.956      0.991      0.596\n",
      "                  Moon         42         43      0.852      0.977      0.978      0.707\n",
      "Speed: 0.5ms preprocess, 4.7ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\constellation_detector12\u001b[0m\n",
      "Evaluating model performance...\n",
      "Ultralytics 8.3.112  Python-3.11.5 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "Model summary (fused): 72 layers, 11,131,776 parameters, 0 gradients, 28.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 398.0144.9 MB/s, size: 47.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Dell\\Downloads\\Star Constellation\\stars_constellations_dataset\\labels\\val.cache... 146 images, 0 backgrounds, 0 corrupt: 100%|██████████| 146/146 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.878      0.929       0.94      0.571\n",
      "                Aquila         28         28      0.966          1      0.994      0.668\n",
      "                Bootes         34         34      0.925          1      0.995      0.667\n",
      "           Canis Major         29         29      0.937          1      0.995      0.644\n",
      "           Canis Minor         35         35      0.891      0.886       0.95       0.41\n",
      "            Cassiopeia         49         49       0.86          1      0.976      0.586\n",
      "                Cygnus         35         35       0.73      0.971       0.97      0.721\n",
      "                Gemini         36         36          1      0.944      0.972      0.647\n",
      "                   Leo         30         30      0.868          1      0.987      0.662\n",
      "                  Lyra         41         41      0.758      0.976      0.975      0.485\n",
      "                  Moon         40         40      0.759        0.8      0.791       0.35\n",
      "                 Orion         32         32          1          1      0.995      0.712\n",
      "              Pleiades         51         51      0.722      0.471      0.541       0.17\n",
      "           Sagittarius         18         18      0.896      0.962       0.99      0.425\n",
      "                Taurus         27         27      0.915      0.926      0.946      0.643\n",
      "            Ursa Major         33         33      0.969      0.956      0.983      0.622\n",
      "                  Moon         42         43      0.852      0.977      0.985      0.732\n",
      "Speed: 0.4ms preprocess, 6.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\constellation_detector122\u001b[0m\n",
      "\n",
      "Evaluation Metrics:\n",
      "mAP50: 0.9403\n",
      "Precision: 0.9655\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9825\n",
      "Model saved to models/constellation_detector_yolov8s.pt\n",
      "Constellation detection model training and evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "AA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing cuda installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "GPU device name: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying to get preprocessing functions integrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 1530/1530 [01:15<00:00, 20.22it/s]\n",
      "Processing: 100%|██████████| 146/146 [00:06<00:00, 21.43it/s]\n",
      "Processing: 100%|██████████| 74/74 [00:03<00:00, 21.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training YOLOv8s model...\n",
      "New https://pypi.org/project/ultralytics/8.3.114 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.112  Python-3.11.5 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=stars_constellations_dataset_processed/constellation_data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=constellation_detector_processed, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0005, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\constellation_detector_processed\n",
      "Overriding model.yaml nc=80 with nc=16\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2122240  ultralytics.nn.modules.head.Detect           [16, [128, 256, 512]]         \n",
      "Model summary: 129 layers, 11,141,792 parameters, 11,141,776 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 9.03.0 MB/s, size: 52.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Dell\\Downloads\\Star Constellation\\stars_constellations_dataset_processed\\labels\\train... 3060 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3060/3060 [00:05<00:00, 556.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\Dell\\Downloads\\Star Constellation\\stars_constellations_dataset_processed\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 6.81.2 MB/s, size: 46.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Dell\\Downloads\\Star Constellation\\stars_constellations_dataset_processed\\labels\\val... 146 images, 0 backgrounds, 0 corrupt: 100%|██████████| 146/146 [00:00<00:00, 369.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Dell\\Downloads\\Star Constellation\\stars_constellations_dataset_processed\\labels\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\constellation_detector_processed\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0005, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\constellation_detector_processed\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      7.42G      2.567      4.108      2.362         17        640: 100%|██████████| 192/192 [02:08<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.453      0.627      0.558       0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      4.33G      2.189      2.574      2.044         10        640: 100%|██████████| 192/192 [01:38<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.769      0.666      0.826      0.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      4.32G       2.06      2.226      1.957         14        640: 100%|██████████| 192/192 [01:37<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.682      0.841      0.854      0.458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      4.32G      1.967      1.984      1.893         17        640: 100%|██████████| 192/192 [01:37<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.795      0.805      0.845      0.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      4.32G      1.896      1.834      1.845         14        640: 100%|██████████| 192/192 [01:37<00:00,  1.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561        0.8      0.871       0.89      0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      4.32G      1.847      1.707      1.805         14        640: 100%|██████████| 192/192 [01:37<00:00,  1.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.769      0.858      0.896      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      4.32G      1.789      1.612      1.758         19        640: 100%|██████████| 192/192 [01:37<00:00,  1.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561       0.85      0.914      0.916      0.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      4.32G      1.736      1.543      1.724         18        640: 100%|██████████| 192/192 [01:37<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.854      0.945       0.94      0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      4.32G      1.683      1.477      1.688          9        640: 100%|██████████| 192/192 [01:37<00:00,  1.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.867      0.938      0.946      0.546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      4.32G       1.64      1.428      1.661         11        640: 100%|██████████| 192/192 [01:37<00:00,  1.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.886      0.932       0.95      0.559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.298 hours.\n",
      "Optimizer stripped from runs\\detect\\constellation_detector_processed\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from runs\\detect\\constellation_detector_processed\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating runs\\detect\\constellation_detector_processed\\weights\\best.pt...\n",
      "Ultralytics 8.3.112  Python-3.11.5 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "Model summary (fused): 72 layers, 11,131,776 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.885      0.933       0.95      0.559\n",
      "                Aquila         28         28      0.906      0.964      0.941      0.597\n",
      "                Bootes         34         34      0.874          1      0.995      0.626\n",
      "           Canis Major         29         29      0.957          1      0.995       0.68\n",
      "           Canis Minor         35         35      0.948      0.914      0.966      0.397\n",
      "            Cassiopeia         49         49      0.884          1      0.938      0.545\n",
      "                Cygnus         35         35      0.758      0.971      0.941      0.682\n",
      "                Gemini         36         36      0.972      0.956      0.994      0.597\n",
      "                   Leo         30         30      0.866          1      0.991      0.646\n",
      "                  Lyra         41         41      0.711          1      0.973       0.52\n",
      "                  Moon         40         40       0.85        0.9       0.92      0.359\n",
      "                 Orion         32         32      0.983          1      0.995      0.687\n",
      "              Pleiades         51         51       0.89      0.318      0.684      0.197\n",
      "           Sagittarius         18         18      0.858          1      0.968      0.521\n",
      "                Taurus         27         27      0.913      0.926      0.936      0.635\n",
      "            Ursa Major         33         33      0.941          1      0.995      0.592\n",
      "                  Moon         42         43      0.857      0.977       0.97      0.657\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\constellation_detector_processed\u001b[0m\n",
      "Evaluating model performance...\n",
      "Ultralytics 8.3.112  Python-3.11.5 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "Model summary (fused): 72 layers, 11,131,776 parameters, 0 gradients, 28.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 463.080.5 MB/s, size: 57.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Dell\\Downloads\\Star Constellation\\stars_constellations_dataset_processed\\labels\\val.cache... 146 images, 0 backgrounds, 0 corrupt: 100%|██████████| 146/146 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        146        561      0.885      0.931      0.949      0.583\n",
      "                Aquila         28         28      0.907      0.964      0.951      0.621\n",
      "                Bootes         34         34      0.874          1      0.995      0.643\n",
      "           Canis Major         29         29      0.958          1      0.995      0.705\n",
      "           Canis Minor         35         35      0.949      0.914       0.96      0.425\n",
      "            Cassiopeia         49         49      0.884          1      0.938      0.567\n",
      "                Cygnus         35         35      0.758      0.971      0.935      0.699\n",
      "                Gemini         36         36      0.972      0.955      0.994       0.63\n",
      "                   Leo         30         30      0.866          1       0.99      0.676\n",
      "                  Lyra         41         41      0.725          1      0.974      0.539\n",
      "                  Moon         40         40      0.856      0.894       0.93       0.38\n",
      "                 Orion         32         32          1          1      0.995      0.713\n",
      "              Pleiades         51         51      0.832      0.292      0.658      0.215\n",
      "           Sagittarius         18         18      0.858          1      0.965      0.533\n",
      "                Taurus         27         27      0.913      0.926      0.936      0.674\n",
      "            Ursa Major         33         33      0.941          1      0.995      0.628\n",
      "                  Moon         42         43      0.857      0.977      0.977      0.681\n",
      "Speed: 0.6ms preprocess, 9.9ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\constellation_detector_processed2\u001b[0m\n",
      "\n",
      "Evaluation Metrics:\n",
      "mAP50: 0.9492\n",
      "Precision: 0.9067\n",
      "Recall: 0.9643\n",
      "F1 Score: 0.9346\n",
      "Model saved to models/constellation_detector_processed_yolov8s.pt\n",
      "Processed constellation detection model training and evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# Configuration\n",
    "DATASET_PATH = \"stars_constellations_dataset\"  # Path to dataset\n",
    "IMG_SIZE = 640  # Target image size\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0005\n",
    "MODEL_TYPE = \"yolov8s.pt\"  # Using the small variant (11.2M parameters)\n",
    "\n",
    "# Define constellation classes (16 classes)\n",
    "CLASSES = [\n",
    "    \"Aquila\", \"Bootes\", \"Canis Major\", \"Canis Minor\", \"Cassiopeia\",\n",
    "    \"Cygnus\", \"Gemini\", \"Leo\", \"Lyra\", \"Moon\", \n",
    "    \"Orion\", \"Pleiades\", \"Sagittarius\", \"Taurus\", \"Ursa Major\", \"Moon\"\n",
    "]\n",
    "\n",
    "def create_dataset_structure():\n",
    "    \"\"\"\n",
    "    Create the necessary directory structure for YOLOv8 format\n",
    "    \"\"\"\n",
    "    os.makedirs(f\"{DATASET_PATH}/images/train\", exist_ok=True)\n",
    "    os.makedirs(f\"{DATASET_PATH}/images/val\", exist_ok=True)\n",
    "    os.makedirs(f\"{DATASET_PATH}/images/test\", exist_ok=True)\n",
    "    os.makedirs(f\"{DATASET_PATH}/labels/train\", exist_ok=True)\n",
    "    os.makedirs(f\"{DATASET_PATH}/labels/val\", exist_ok=True)\n",
    "    os.makedirs(f\"{DATASET_PATH}/labels/test\", exist_ok=True)\n",
    "    \n",
    "    return\n",
    "\n",
    "def create_yolov8_structure():\n",
    "    # Create a new dataset directory for preprocessed data\n",
    "    processed_dir = f\"{DATASET_PATH}_processed\"\n",
    "    \n",
    "    # Create proper YOLOv8 structure\n",
    "    os.makedirs(f\"{processed_dir}/images/train\", exist_ok=True)\n",
    "    os.makedirs(f\"{processed_dir}/images/val\", exist_ok=True)\n",
    "    os.makedirs(f\"{processed_dir}/images/test\", exist_ok=True)\n",
    "    os.makedirs(f\"{processed_dir}/labels/train\", exist_ok=True)\n",
    "    os.makedirs(f\"{processed_dir}/labels/val\", exist_ok=True)\n",
    "    os.makedirs(f\"{processed_dir}/labels/test\", exist_ok=True)\n",
    "    \n",
    "    return processed_dir\n",
    "\n",
    "def preprocess_dataset(train_only=False):\n",
    "    \"\"\"\n",
    "    Preprocess both images and labels, ensuring both are properly copied and aligned\n",
    "    \"\"\"\n",
    "    # Define directory paths\n",
    "    raw_images_dir = f\"{DATASET_PATH}/images\"\n",
    "    raw_labels_dir = f\"{DATASET_PATH}/labels\"\n",
    "    proc_images_dir = f\"{DATASET_PATH}/preprocessed_images\"\n",
    "    proc_labels_dir = f\"{DATASET_PATH}/preprocessed_labels\"\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(f\"{proc_images_dir}/train\", exist_ok=True)\n",
    "    os.makedirs(f\"{proc_labels_dir}/train\", exist_ok=True)\n",
    "    \n",
    "    if not train_only:\n",
    "        os.makedirs(f\"{proc_images_dir}/val\", exist_ok=True)\n",
    "        os.makedirs(f\"{proc_labels_dir}/val\", exist_ok=True)\n",
    "        os.makedirs(f\"{proc_images_dir}/test\", exist_ok=True)\n",
    "        os.makedirs(f\"{proc_labels_dir}/test\", exist_ok=True)\n",
    "    \n",
    "    # Process training set\n",
    "    print(\"Processing training images and labels...\")\n",
    "    process_subset(\n",
    "        f\"{raw_images_dir}/train\", \n",
    "        f\"{raw_labels_dir}/train\",\n",
    "        f\"{proc_images_dir}/train\", \n",
    "        f\"{proc_labels_dir}/train\", \n",
    "        augment=True\n",
    "    )\n",
    "    \n",
    "    if not train_only:\n",
    "        # Process validation set\n",
    "        print(\"Processing validation images and labels...\")\n",
    "        process_subset(\n",
    "            f\"{raw_images_dir}/val\", \n",
    "            f\"{raw_labels_dir}/val\",\n",
    "            f\"{proc_images_dir}/val\", \n",
    "            f\"{proc_labels_dir}/val\", \n",
    "            augment=False\n",
    "        )\n",
    "        \n",
    "        # Process test set\n",
    "        print(\"Processing test images and labels...\")\n",
    "        process_subset(\n",
    "            f\"{raw_images_dir}/test\", \n",
    "            f\"{raw_labels_dir}/test\",\n",
    "            f\"{proc_images_dir}/test\", \n",
    "            f\"{proc_labels_dir}/test\", \n",
    "            augment=False\n",
    "        )\n",
    "    \n",
    "    return proc_images_dir, proc_labels_dir\n",
    "\n",
    "def process_subset(img_input_dir, label_input_dir, img_output_dir, label_output_dir, augment=False):\n",
    "    \"\"\"\n",
    "    Process a subset of the dataset, handling both images and labels\n",
    "    \"\"\"\n",
    "    # Get all image files\n",
    "    image_files = [f for f in os.listdir(img_input_dir) if f.endswith(('.jpg', '.png', '.jpeg', '.tif', '.tiff'))]\n",
    "    \n",
    "    for img_file in tqdm(image_files, desc=\"Processing\"):\n",
    "        # Get image base name without extension\n",
    "        img_base = os.path.splitext(img_file)[0]\n",
    "        img_path = os.path.join(img_input_dir, img_file)\n",
    "        label_file = f\"{img_base}.txt\"\n",
    "        label_path = os.path.join(label_input_dir, label_file)\n",
    "        \n",
    "        # Skip if label doesn't exist\n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Warning: No label file found for {img_file}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        # Read and preprocess image\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to load image: {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Basic preprocessing\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        l, a, b = cv2.split(cv2.cvtColor(img, cv2.COLOR_RGB2LAB))\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        l = clahe.apply(l)\n",
    "        img = cv2.cvtColor(cv2.merge((l, a, b)), cv2.COLOR_LAB2RGB)\n",
    "        img_resized = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Save preprocessed image\n",
    "        img_output_path = os.path.join(img_output_dir, img_file)\n",
    "        cv2.imwrite(img_output_path, cv2.cvtColor(img_resized, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        # Copy label file (no transformation needed for basic resize)\n",
    "        label_output_path = os.path.join(label_output_dir, label_file)\n",
    "        shutil.copy(label_path, label_output_path)\n",
    "        \n",
    "        # Simple augmentation\n",
    "        if augment:\n",
    "            # Rotation 90 degrees\n",
    "            height, width = img_resized.shape[:2]\n",
    "            matrix = cv2.getRotationMatrix2D((width/2, height/2), 90, 1)\n",
    "            rotated = cv2.warpAffine(img_resized, matrix, (width, height))\n",
    "            rot_img_path = os.path.join(img_output_dir, f\"rot_90_{img_file}\")\n",
    "            cv2.imwrite(rot_img_path, cv2.cvtColor(rotated, cv2.COLOR_RGB2BGR))\n",
    "            \n",
    "            # Transform labels for rotation (this is the tricky part)\n",
    "            rot_label_path = os.path.join(label_output_dir, f\"rot_90_{img_base}.txt\")\n",
    "            with open(label_path, 'r') as f_in, open(rot_label_path, 'w') as f_out:\n",
    "                for line in f_in:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:  # class x y width height\n",
    "                        cls = parts[0]\n",
    "                        x, y = float(parts[1]), float(parts[2])\n",
    "                        w, h = float(parts[3]), float(parts[4])\n",
    "                        \n",
    "                        # For 90 degree rotation: (x,y) -> (1-y,x)\n",
    "                        new_x = 1.0 - y\n",
    "                        new_y = x\n",
    "                        # Swap width and height\n",
    "                        new_w, new_h = h, w\n",
    "                        \n",
    "                        f_out.write(f\"{cls} {new_x:.6f} {new_y:.6f} {new_w:.6f} {new_h:.6f}\\n\")\n",
    "    \n",
    "    return\n",
    "    \n",
    "\n",
    "def split_dataset(image_list, labels_list, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Split dataset into train, validation and test sets based on specified ratio\n",
    "    \"\"\"\n",
    "    # First split into train and temporary sets\n",
    "    train_images, temp_images, train_labels, temp_labels = train_test_split(\n",
    "        image_list, labels_list, test_size=(val_ratio + test_ratio), random_state=42\n",
    "    )\n",
    "    \n",
    "    # Split temporary set into validation and test sets\n",
    "    val_ratio_adjusted = val_ratio / (val_ratio + test_ratio)\n",
    "    val_images, test_images, val_labels, test_labels = train_test_split(\n",
    "        temp_images, temp_labels, test_size=(1 - val_ratio_adjusted), random_state=42\n",
    "    )\n",
    "    \n",
    "    return (train_images, train_labels), (val_images, val_labels), (test_images, test_labels)\n",
    "\n",
    "def create_yaml_config(dataset_path):\n",
    "    config = {\n",
    "        'path': os.path.abspath(dataset_path),\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'test': 'images/test',\n",
    "        'names': {i: name for i, name in enumerate(CLASSES)}\n",
    "    }\n",
    "    \n",
    "    with open(f\"{dataset_path}/constellation_data.yaml\", 'w') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False)\n",
    "    \n",
    "    return f\"{dataset_path}/constellation_data.yaml\"\n",
    "\n",
    "def train_model(yaml_path):\n",
    "    \"\"\"\n",
    "    Train the YOLOv8s model using the dataset\n",
    "    \"\"\"\n",
    "    # Load a pretrained YOLOv8s model\n",
    "    model = YOLO(MODEL_TYPE)\n",
    "    \n",
    "    # Train the model\n",
    "    results = model.train(\n",
    "        data=yaml_path,\n",
    "        epochs=EPOCHS,\n",
    "        batch=BATCH_SIZE,\n",
    "        imgsz=IMG_SIZE,\n",
    "        optimizer=\"Adam\",  # As per requirements\n",
    "        lr0=LEARNING_RATE,  # Initial learning rate\n",
    "        conf=0.25,  # Detection confidence threshold\n",
    "        name=\"constellation_detector\",\n",
    "        device=0 if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "    \n",
    "    return model, results\n",
    "\n",
    "def evaluate_model(model):\n",
    "    \"\"\"\n",
    "    Evaluate model performance using mAP50 and other metrics\n",
    "    \"\"\"\n",
    "    # Validate the model\n",
    "    results = model.val(conf=0.1)\n",
    "    \n",
    "    # Handle potentially multi-element arrays by taking the first element if needed\n",
    "    def safe_convert(value):\n",
    "        try:\n",
    "            # Try direct conversion first\n",
    "            return float(value)\n",
    "        except (TypeError, ValueError):\n",
    "            # If that fails, try to access the first element\n",
    "            if hasattr(value, '__len__') and len(value) > 0:\n",
    "                return float(value[0])\n",
    "            # If that also fails, return a default value\n",
    "            return 0.0\n",
    "    \n",
    "    metrics = {\n",
    "        \"mAP50\": safe_convert(results.box.map50),\n",
    "        \"precision\": safe_convert(results.box.p),\n",
    "        \"recall\": safe_convert(results.box.r),\n",
    "        \"f1\": safe_convert(results.box.f1)\n",
    "    }\n",
    "    \n",
    "    print(\"\\nEvaluation Metrics:\")\n",
    "    print(f\"mAP50: {metrics['mAP50']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def detect_constellations(model, image_path):\n",
    "    \"\"\"\n",
    "    Perform constellation detection on a single image\n",
    "    \"\"\"\n",
    "    # Run inference\n",
    "    results = model.predict(image_path, conf=0.25)\n",
    "    \n",
    "    # Process results\n",
    "    result = results[0]\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(result.plot())\n",
    "    plt.axis('off')\n",
    "    plt.title('Constellation Detection')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detections\n",
    "    for box in result.boxes:\n",
    "        class_id = int(box.cls[0].item())\n",
    "        confidence = box.conf[0].item()\n",
    "        coordinates = box.xyxy[0].tolist()\n",
    "        print(f\"Detected {CLASSES[class_id]} with confidence {confidence:.2f} at {coordinates}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    # Create new dataset structure with proper YOLOv8 format\n",
    "    processed_dir = create_yolov8_structure()\n",
    "    \n",
    "    # Preprocess and copy data from original dataset to new structure\n",
    "    print(\"Preprocessing dataset...\")\n",
    "    \n",
    "    # Process training set - copy from original to new structure\n",
    "    process_subset(\n",
    "        f\"{DATASET_PATH}/images/train\", \n",
    "        f\"{DATASET_PATH}/labels/train\",\n",
    "        f\"{processed_dir}/images/train\", \n",
    "        f\"{processed_dir}/labels/train\", \n",
    "        augment=True\n",
    "    )\n",
    "    \n",
    "    # Process validation set\n",
    "    process_subset(\n",
    "        f\"{DATASET_PATH}/images/val\", \n",
    "        f\"{DATASET_PATH}/labels/val\",\n",
    "        f\"{processed_dir}/images/val\", \n",
    "        f\"{processed_dir}/labels/val\", \n",
    "        augment=False\n",
    "    )\n",
    "    \n",
    "    # Process test set\n",
    "    process_subset(\n",
    "        f\"{DATASET_PATH}/images/test\", \n",
    "        f\"{DATASET_PATH}/labels/test\",\n",
    "        f\"{processed_dir}/images/test\", \n",
    "        f\"{processed_dir}/labels/test\", \n",
    "        augment=False\n",
    "    )\n",
    "    \n",
    "    # Create YAML config for the new structure\n",
    "    yaml_path = create_yaml_config(processed_dir)\n",
    "    \n",
    "    # Train using the properly structured preprocessed dataset\n",
    "    print(\"Training YOLOv8s model...\")\n",
    "    model = YOLO(MODEL_TYPE)\n",
    "    \n",
    "    results = model.train(\n",
    "        data=yaml_path,\n",
    "        epochs=EPOCHS,\n",
    "        batch=BATCH_SIZE,\n",
    "        imgsz=IMG_SIZE,\n",
    "        optimizer=\"Adam\",  \n",
    "        lr0=LEARNING_RATE,\n",
    "        name=\"constellation_detector_processed\"\n",
    "    )\n",
    "    \n",
    "    # Evaluate and save the model\n",
    "    print(\"Evaluating model performance...\")\n",
    "    metrics = evaluate_model(model)\n",
    "    \n",
    "    model_save_path = \"models/constellation_detector_processed_yolov8s.pt\"\n",
    "    os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "    model.save(model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "    \n",
    "    print(\"Processed constellation detection model training and evaluation complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
