{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# constellation detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please prepare your dataset by placing images and labels in the appropriate directories\n",
      "Created YAML configuration at stars_constellations_dataset/constellation_data.yaml\n",
      "Training YOLOv11s model with AdamW optimizer (lr=0.001) for star constellation detection...\n",
      "Ultralytics 8.3.133  Python-3.13.3 torch-2.7.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=0.25, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=stars_constellations_dataset/constellation_data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=constellation_detector_adamw, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\constellation_detector_adamw, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.01, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=16\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    825600  ultralytics.nn.modules.head.Detect           [16, [128, 256, 512]]         \n",
      "YOLO11s summary: 181 layers, 9,433,984 parameters, 9,433,968 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 493/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 213.174.0 MB/s, size: 35.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Dell\\Downloads\\Star Constellation (2)\\Star Constellation\\Star Constellation\\stars_constellations_dataset\\labels\\train.cache... 1530 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1530/1530 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 151.769.0 MB/s, size: 48.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Dell\\Downloads\\Star Constellation (2)\\Star Constellation\\Star Constellation\\stars_constellations_dataset\\labels\\val.cache... 14 images, 0 backgrounds, 0 corrupt: 100%|██████████| 14/14 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\constellation_detector_adamw\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.01), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\constellation_detector_adamw\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      4.24G      2.261        3.3      1.933         38        640: 100%|██████████| 96/96 [00:54<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         14         75      0.427      0.514      0.521      0.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      4.31G      1.845      1.282      1.602         37        640: 100%|██████████| 96/96 [00:52<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         14         75      0.643      0.649      0.725      0.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      4.31G      1.776      1.114      1.535         39        640: 100%|██████████| 96/96 [00:51<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         14         75      0.644      0.626      0.673      0.401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      4.33G      1.712       1.02      1.485         27        640: 100%|██████████| 96/96 [00:51<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         14         75      0.725      0.857      0.899      0.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10       4.5G      1.658      0.923      1.444         23        640: 100%|██████████| 96/96 [00:52<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         14         75      0.808       0.79      0.845       0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10       4.3G      1.575     0.8395      1.412         41        640: 100%|██████████| 96/96 [00:52<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         14         75      0.854      0.967       0.91      0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      4.31G      1.533     0.7848      1.374         33        640: 100%|██████████| 96/96 [00:52<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         14         75       0.84      0.889      0.895      0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      4.49G      1.475     0.7372      1.329         43        640: 100%|██████████| 96/96 [00:52<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         14         75      0.932      0.928       0.96      0.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      4.33G      1.424     0.6845      1.305         40        640: 100%|██████████| 96/96 [00:52<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         14         75      0.923      0.977      0.937      0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10       4.5G      1.392     0.6562      1.292         33        640: 100%|██████████| 96/96 [00:52<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         14         75      0.916      0.977      0.975      0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.154 hours.\n",
      "Optimizer stripped from runs\\detect\\constellation_detector_adamw\\weights\\last.pt, 19.2MB\n",
      "Optimizer stripped from runs\\detect\\constellation_detector_adamw\\weights\\best.pt, 19.2MB\n",
      "\n",
      "Validating runs\\detect\\constellation_detector_adamw\\weights\\best.pt...\n",
      "Ultralytics 8.3.133  Python-3.13.3 torch-2.7.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,418,992 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         14         75      0.916      0.977      0.975      0.564\n",
      "                Bootes          1          1      0.333          1      0.995      0.597\n",
      "           Canis Major          9          9          1          1      0.995        0.7\n",
      "           Canis Minor          9          9      0.889      0.889      0.852      0.325\n",
      "            Cassiopeia          5          5          1          1      0.995      0.487\n",
      "                Gemini          9          9          1          1      0.995       0.68\n",
      "                   Leo          9          9          1          1      0.995      0.658\n",
      "                  Moon          3          3          1          1      0.995       0.52\n",
      "                 Orion          9          9          1          1      0.995      0.637\n",
      "              Pleiades          7          7      0.857      0.857      0.918      0.375\n",
      "            Ursa Major          9          9          1          1      0.995      0.572\n",
      "                  Moon          5          5          1          1      0.995      0.652\n",
      "Speed: 0.1ms preprocess, 5.7ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\constellation_detector_adamw\u001b[0m\n",
      "Evaluating model performance...\n",
      "Ultralytics 8.3.133  Python-3.13.3 torch-2.7.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,418,992 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 500.664.1 MB/s, size: 59.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Dell\\Downloads\\Star Constellation (2)\\Star Constellation\\Star Constellation\\stars_constellations_dataset\\labels\\val.cache... 14 images, 0 backgrounds, 0 corrupt: 100%|██████████| 14/14 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         14         75      0.929      0.977      0.976      0.563\n",
      "                Bootes          1          1      0.333          1      0.995      0.597\n",
      "           Canis Major          9          9          1          1      0.995        0.7\n",
      "           Canis Minor          9          9      0.889      0.889      0.852      0.316\n",
      "            Cassiopeia          5          5          1          1      0.995      0.487\n",
      "                Gemini          9          9          1          1      0.995       0.68\n",
      "                   Leo          9          9          1          1      0.995      0.658\n",
      "                  Moon          3          3          1          1      0.995       0.52\n",
      "                 Orion          9          9          1          1      0.995      0.637\n",
      "              Pleiades          7          7          1      0.857      0.928      0.377\n",
      "            Ursa Major          9          9          1          1      0.995      0.572\n",
      "                  Moon          5          5          1          1      0.995      0.652\n",
      "Speed: 0.2ms preprocess, 10.1ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\constellation_detector_adamw2\u001b[0m\n",
      "\n",
      "Evaluation Metrics:\n",
      "• mAP50: 0.976\n",
      "• Precision: 0.000\n",
      "• Recall: 0.000\n",
      "• F1 Score: 0.000\n",
      "Ultralytics 8.3.133  Python-3.13.3 torch-2.7.0+cu118 CPU (Intel Core(TM) i7-8700K 3.70GHz)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs\\detect\\constellation_detector_adamw\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 20, 8400) (18.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.7.0+cu118...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  2.9s, saved as 'runs\\detect\\constellation_detector_adamw\\weights\\best.torchscript' (36.5 MB)\n",
      "\n",
      "Export complete (3.2s)\n",
      "Results saved to \u001b[1mC:\\Users\\Dell\\Downloads\\Star Constellation (2)\\Star Constellation\\Star Constellation\\runs\\detect\\constellation_detector_adamw\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs\\detect\\constellation_detector_adamw\\weights\\best.torchscript imgsz=640  \n",
      "Validate:        yolo val task=detect model=runs\\detect\\constellation_detector_adamw\\weights\\best.torchscript imgsz=640 data=stars_constellations_dataset/constellation_data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Model saved to models/constellation_detector_yolo11s_adamw.pt\n",
      "Constellation detection model training and evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "DATASET_PATH = \"stars_constellations_dataset\"  # Path to dataset\n",
    "IMG_SIZE = 640  # Target image size\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001  # Changed to 0.001 as requested\n",
    "MODEL_TYPE = \"yolo11s.pt\"  # Changed to YOLOv11s (small variant)\n",
    "\n",
    "# Define constellation classes (16 classes as per requirements)\n",
    "CLASSES = [\n",
    "    \"Aquila\", \"Bootes\", \"Canis Major\", \"Canis Minor\", \"Cassiopeia\",\n",
    "    \"Cygnus\", \"Gemini\", \"Leo\", \"Lyra\", \"Moon\", \n",
    "    \"Orion\", \"Pleiades\", \"Sagittarius\", \"Taurus\", \"Ursa Major\", \"Moon\"\n",
    "]\n",
    "\n",
    "def create_dataset_structure():\n",
    "    \"\"\"\n",
    "    Create the necessary directory structure for YOLOv11 format\n",
    "    \"\"\"\n",
    "    os.makedirs(f\"{DATASET_PATH}/images/train\", exist_ok=True)\n",
    "    os.makedirs(f\"{DATASET_PATH}/images/val\", exist_ok=True)\n",
    "    os.makedirs(f\"{DATASET_PATH}/images/test\", exist_ok=True)\n",
    "    os.makedirs(f\"{DATASET_PATH}/labels/train\", exist_ok=True)\n",
    "    os.makedirs(f\"{DATASET_PATH}/labels/val\", exist_ok=True)\n",
    "    os.makedirs(f\"{DATASET_PATH}/labels/test\", exist_ok=True)\n",
    "    \n",
    "    return\n",
    "\n",
    "def preprocess_images(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Preprocess images by resizing to 640x640 as per requirements\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    image_files = [f for f in os.listdir(input_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    for img_file in tqdm(image_files, desc=\"Preprocessing images\"):\n",
    "        img_path = os.path.join(input_dir, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        # Check if image loaded correctly\n",
    "        if img is None:\n",
    "            print(f\"Failed to load image: {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Resize to square 640x640\n",
    "        img_resized = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        # Optional: Apply additional preprocessing specifically for star images\n",
    "        # Increase contrast to make stars more visible\n",
    "        img_enhanced = enhance_star_visibility(img_resized)\n",
    "        \n",
    "        # Save the preprocessed image\n",
    "        output_path = os.path.join(output_dir, img_file)\n",
    "        cv2.imwrite(output_path, img_enhanced)\n",
    "    \n",
    "    return\n",
    "\n",
    "def enhance_star_visibility(image):\n",
    "    \"\"\"\n",
    "    Apply image processing to enhance star visibility\n",
    "    \"\"\"\n",
    "    # Convert to grayscale for brightness analysis\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image.copy()\n",
    "    \n",
    "    # Apply histogram equalization to enhance contrast\n",
    "    equalized = cv2.equalizeHist(gray)\n",
    "    \n",
    "    # If original image was color, convert back to color\n",
    "    if len(image.shape) == 3:\n",
    "        # Create a 3-channel image from the equalized grayscale\n",
    "        equalized_color = cv2.cvtColor(equalized, cv2.COLOR_GRAY2BGR)\n",
    "        return equalized_color\n",
    "    \n",
    "    return equalized\n",
    "\n",
    "def split_dataset(image_list, labels_list, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Split dataset into train, validation and test sets based on specified ratio\n",
    "    \"\"\"\n",
    "    # First split into train and temporary sets\n",
    "    train_images, temp_images, train_labels, temp_labels = train_test_split(\n",
    "        image_list, labels_list, test_size=(val_ratio + test_ratio), random_state=42\n",
    "    )\n",
    "    \n",
    "    # Split temporary set into validation and test sets\n",
    "    val_ratio_adjusted = val_ratio / (val_ratio + test_ratio)\n",
    "    val_images, test_images, val_labels, test_labels = train_test_split(\n",
    "        temp_images, temp_labels, test_size=(1 - val_ratio_adjusted), random_state=42\n",
    "    )\n",
    "    \n",
    "    return (train_images, train_labels), (val_images, val_labels), (test_images, test_labels)\n",
    "\n",
    "def create_yaml_config():\n",
    "    \"\"\"\n",
    "    Create YAML configuration file for YOLOv11 training\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        'path': os.path.abspath(DATASET_PATH),\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'test': 'images/test',\n",
    "        'names': {i: name for i, name in enumerate(CLASSES)}\n",
    "    }\n",
    "    \n",
    "    with open(f\"{DATASET_PATH}/constellation_data.yaml\", 'w') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"Created YAML configuration at {DATASET_PATH}/constellation_data.yaml\")\n",
    "    return f\"{DATASET_PATH}/constellation_data.yaml\"\n",
    "\n",
    "def train_model(yaml_path):\n",
    "    \"\"\"\n",
    "    Train the YOLOv11s model using the dataset with AdamW optimizer\n",
    "    \"\"\"\n",
    "    # Load a pretrained YOLOv11s model\n",
    "    model = YOLO(MODEL_TYPE)\n",
    "    \n",
    "    # Train the model with optimized hyperparameters for star detection\n",
    "    # Note: YOLOv11 uses AdamW by default for most training scenarios\n",
    "    results = model.train(\n",
    "        data=yaml_path,\n",
    "        epochs=EPOCHS,\n",
    "        batch=BATCH_SIZE,\n",
    "        imgsz=IMG_SIZE,\n",
    "        optimizer=\"AdamW\",  # Changed to AdamW optimizer\n",
    "        lr0=LEARNING_RATE,  # Initial learning rate set to 0.001\n",
    "        lrf=0.01,          # Final learning rate as a fraction of lr0\n",
    "        momentum=0.937,    # SGD momentum/Adam beta1 (not used with AdamW)\n",
    "        weight_decay=0.01,  # AdamW weight decay - increased for better regularization\n",
    "        warmup_epochs=3.0,    # Warmup epochs for learning rate\n",
    "        warmup_momentum=0.8,  # Warmup initial momentum\n",
    "        box=7.5,           # Box loss gain (higher for better bounding box precision)\n",
    "        cls=0.5,           # Class loss gain (lower for astronomical objects with less class variation)\n",
    "        hsv_h=0.015,       # Image HSV-Hue augmentation (fraction)\n",
    "        hsv_s=0.7,         # Image HSV-Saturation augmentation (fraction)\n",
    "        hsv_v=0.4,         # Image HSV-Value augmentation (fraction) - important for brightness variations\n",
    "        degrees=0.0,       # Image rotation (+/- deg) - minimal rotation for astronomical images\n",
    "        translate=0.1,     # Image translation (+/- fraction)\n",
    "        scale=0.5,         # Image scale (+/- gain) - helps with detection at different scales\n",
    "        fliplr=0.5,        # Image flip left-right (probability)\n",
    "        mosaic=1.0,        # Mosaic augmentation (probability)\n",
    "        mixup=0.0,         # Mixup augmentation (probability) - disabled as it might confuse constellation patterns\n",
    "        copy_paste=0.0,    # Segment copy-paste (probability) - not needed for star detection\n",
    "        conf=0.25,         # Detection confidence threshold\n",
    "        iou=0.7,           # Intersection over union (IoU) threshold for NMS\n",
    "        max_det=300,       # Maximum detections per image\n",
    "        name=\"constellation_detector_adamw\",  # Updated name to reflect AdamW usage\n",
    "        device=0,          # Use your GPU\n",
    "        amp=True           # Enable Automatic Mixed Precision for better performance with AdamW\n",
    "    )\n",
    "    \n",
    "    return model, results\n",
    "\n",
    "def evaluate_model(model):\n",
    "    \"\"\"\n",
    "    Evaluate model performance using mAP50 and other metrics\n",
    "    \"\"\"\n",
    "    # Validate the model (this will calculate mAP50 as specified in requirements)\n",
    "    results = model.val()\n",
    "    \n",
    "    # Safely convert metrics to float values\n",
    "    def safe_float_convert(value):\n",
    "        try:\n",
    "            if hasattr(value, 'item'):  # Handle tensor values\n",
    "                return value.item()\n",
    "            elif hasattr(value, '__len__') and len(value) == 1:  # Handle length-1 arrays\n",
    "                return float(value[0])\n",
    "            else:\n",
    "                return float(value)  # Try direct conversion\n",
    "        except (TypeError, ValueError, IndexError):\n",
    "            return 0.0  # Default value if conversion fails\n",
    "    \n",
    "    metrics = {\n",
    "        \"mAP50\": safe_float_convert(results.box.map50),\n",
    "        \"precision\": safe_float_convert(results.box.p),\n",
    "        \"recall\": safe_float_convert(results.box.r),\n",
    "        \"f1\": safe_float_convert(results.box.f1)\n",
    "    }\n",
    "    \n",
    "    print(\"\\nEvaluation Metrics:\")\n",
    "    print(f\"• mAP50: {metrics['mAP50']:.3f}\")\n",
    "    print(f\"• Precision: {metrics['precision']:.3f}\")\n",
    "    print(f\"• Recall: {metrics['recall']:.3f}\")\n",
    "    print(f\"• F1 Score: {metrics['f1']:.3f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def detect_constellations(model, image_path):\n",
    "    \"\"\"\n",
    "    Perform constellation detection on a single image with optimized inference parameters\n",
    "    \"\"\"\n",
    "    # Run inference with parameters optimized for star detection\n",
    "    results = model.predict(\n",
    "        image_path, \n",
    "        conf=0.25,       # Detection confidence threshold\n",
    "        iou=0.7,         # NMS IoU threshold\n",
    "        max_det=300,     # Maximum number of detections per image\n",
    "        augment=True     # TTA (Test Time Augmentation)\n",
    "    )\n",
    "    \n",
    "    # Process results\n",
    "    result = results[0]\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(result.plot())\n",
    "    plt.axis('off')\n",
    "    plt.title('Constellation Detection')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detections\n",
    "    for box in result.boxes:\n",
    "        class_id = int(box.cls[0].item())\n",
    "        confidence = box.conf[0].item()\n",
    "        coordinates = box.xyxy[0].tolist()\n",
    "        print(f\"Detected {CLASSES[class_id]} with confidence {confidence:.2f} at {coordinates}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    # Step 1: Create dataset structure\n",
    "    create_dataset_structure()\n",
    "    \n",
    "    # Note: At this point you would need to:\n",
    "    # 1. Collect/prepare your 1,750 labeled constellation images\n",
    "    # 2. Convert annotations to YOLO format\n",
    "    # 3. Place images and labels in the appropriate directories\n",
    "    print(\"Please prepare your dataset by placing images and labels in the appropriate directories\")\n",
    "    \n",
    "    # Step 2: Create YAML configuration\n",
    "    yaml_path = create_yaml_config()\n",
    "    \n",
    "    # Step 3: Train the model with AdamW optimizer\n",
    "    print(\"Training YOLOv11s model with AdamW optimizer (lr=0.001) for star constellation detection...\")\n",
    "    model, training_results = train_model(yaml_path)\n",
    "    \n",
    "    # Step 4: Evaluate the model\n",
    "    print(\"Evaluating model performance...\")\n",
    "    metrics = evaluate_model(model)\n",
    "    \n",
    "    # Save the trained model\n",
    "    model_save_path = \"models/constellation_detector_yolo11s_adamw.pt\"\n",
    "    os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "    model.export(format=\"torchscript\")  # Export to PyTorch format\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "    \n",
    "    # For demonstration, you would use your own test image\n",
    "    # detect_constellations(model, \"path_to_test_image.jpg\")\n",
    "    \n",
    "    print(\"Constellation detection model training and evaluation complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing cuda installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "GPU device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce GTX 1070\n",
      "PyTorch version: 2.7.0+cu118\n",
      "Built with CUDA: 11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda if torch.cuda.is_available() else 'N/A'}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name()}\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Built with CUDA: {torch.version.cuda}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "constellation_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
