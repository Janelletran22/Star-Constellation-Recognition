{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# constellation detection system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please prepare your dataset by placing images and labels in the appropriate directories\n",
      "Created YAML configuration at stars_constellations_dataset/constellation_data.yaml\n",
      "Training YOLOv8s model...\n",
      "Ultralytics 8.3.128  Python-3.13.3 torch-2.7.0+cu118 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=False, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=0.25, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=stars_constellations_dataset/constellation_data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=constellation_detector19, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\constellation_detector19, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=16\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2122240  ultralytics.nn.modules.head.Detect           [16, [128, 256, 512]]         \n",
      "Model summary: 129 layers, 11,141,792 parameters, 11,141,776 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 304.392.2 MB/s, size: 35.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Riran\\Downloads\\Star Constellation\\Star Constellation\\stars_constellations_dataset\\labels\\train.cache... 1530 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1530/1530 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 232.145.0 MB/s, size: 48.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Riran\\Downloads\\Star Constellation\\Star Constellation\\stars_constellations_dataset\\labels\\val.cache... 25 images, 0 backgrounds, 0 corrupt: 100%|██████████| 25/25 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\constellation_detector19\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0005, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\constellation_detector19\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      6.64G      2.277      3.031       1.94         38        640: 100%|██████████| 96/96 [00:45<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25        133       0.18        0.2      0.237      0.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      6.52G      1.855      1.407      1.584         37        640: 100%|██████████| 96/96 [00:44<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25        133       0.59      0.586      0.603      0.309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      6.52G      1.735       1.12      1.486         39        640: 100%|██████████| 96/96 [00:44<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25        133      0.759      0.797      0.829        0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      6.52G      1.685      1.021      1.444         27        640: 100%|██████████| 96/96 [00:45<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25        133       0.72      0.888       0.89      0.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      6.52G      1.581     0.9005      1.385         23        640: 100%|██████████| 96/96 [00:45<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25        133      0.835      0.852      0.874      0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      6.52G      1.532     0.8195      1.358         41        640: 100%|██████████| 96/96 [00:45<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25        133      0.831      0.912      0.918      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      6.52G      1.507     0.7764      1.335         33        640: 100%|██████████| 96/96 [00:44<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25        133       0.86      0.876      0.899      0.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      6.52G       1.45      0.735      1.301         43        640: 100%|██████████| 96/96 [00:43<00:00,  2.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25        133      0.845      0.912      0.913      0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      6.52G      1.404     0.6818      1.274         40        640: 100%|██████████| 96/96 [00:44<00:00,  2.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25        133       0.87      0.904      0.915      0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      6.52G      1.388     0.6525      1.273         33        640: 100%|██████████| 96/96 [00:44<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25        133      0.863      0.892      0.904      0.573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.133 hours.\n",
      "Optimizer stripped from runs\\detect\\constellation_detector19\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from runs\\detect\\constellation_detector19\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating runs\\detect\\constellation_detector19\\weights\\best.pt...\n",
      "Ultralytics 8.3.128  Python-3.13.3 torch-2.7.0+cu118 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 8192MiB)\n",
      "Model summary (fused): 72 layers, 11,131,776 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25        133      0.863      0.892      0.904      0.573\n",
      "                Bootes          1          1       0.25          1      0.995      0.796\n",
      "           Canis Major         17         17          1          1      0.995      0.703\n",
      "           Canis Minor         17         17      0.882      0.882       0.83      0.383\n",
      "            Cassiopeia          8          8          1          1      0.995       0.52\n",
      "                Gemini         17         17          1          1      0.995      0.608\n",
      "                   Leo         11         11      0.917          1      0.995      0.672\n",
      "                  Moon          5          5        0.5        0.6      0.486      0.134\n",
      "                 Orion         17         17          1          1      0.995      0.769\n",
      "              Pleiades         15         15          1      0.333      0.667      0.274\n",
      "            Ursa Major         17         17      0.944          1      0.995       0.67\n",
      "                  Moon          8          8          1          1      0.995      0.777\n",
      "Speed: 0.3ms preprocess, 4.7ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\constellation_detector19\u001b[0m\n",
      "Evaluating model performance...\n",
      "Ultralytics 8.3.128  Python-3.13.3 torch-2.7.0+cu118 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 8192MiB)\n",
      "Model summary (fused): 72 layers, 11,131,776 parameters, 0 gradients, 28.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 637.0147.6 MB/s, size: 49.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Riran\\Downloads\\Star Constellation\\Star Constellation\\stars_constellations_dataset\\labels\\val.cache... 25 images, 0 backgrounds, 0 corrupt: 100%|██████████| 25/25 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25        133      0.863      0.892      0.904      0.573\n",
      "                Bootes          1          1       0.25          1      0.995      0.796\n",
      "           Canis Major         17         17          1          1      0.995      0.703\n",
      "           Canis Minor         17         17      0.882      0.882       0.83      0.383\n",
      "            Cassiopeia          8          8          1          1      0.995       0.52\n",
      "                Gemini         17         17          1          1      0.995      0.608\n",
      "                   Leo         11         11      0.917          1      0.995      0.672\n",
      "                  Moon          5          5        0.5        0.6      0.486      0.134\n",
      "                 Orion         17         17          1          1      0.995      0.769\n",
      "              Pleiades         15         15          1      0.333      0.667      0.274\n",
      "            Ursa Major         17         17      0.944          1      0.995       0.67\n",
      "                  Moon          8          8          1          1      0.995      0.777\n",
      "Speed: 8.0ms preprocess, 4.1ms inference, 0.0ms loss, 7.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\constellation_detector192\u001b[0m\n",
      "\n",
      "Evaluation Metrics:\n",
      "mAP50: 0.9039\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Ultralytics 8.3.128  Python-3.13.3 torch-2.7.0+cu118 CPU (Intel Core(TM) i7-9700F 3.00GHz)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs\\detect\\constellation_detector19\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 20, 8400) (21.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.7.0+cu118...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  2.0s, saved as 'runs\\detect\\constellation_detector19\\weights\\best.torchscript' (42.9 MB)\n",
      "\n",
      "Export complete (2.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\Riran\\Downloads\\Star Constellation\\Star Constellation\\runs\\detect\\constellation_detector19\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs\\detect\\constellation_detector19\\weights\\best.torchscript imgsz=640  \n",
      "Validate:        yolo val task=detect model=runs\\detect\\constellation_detector19\\weights\\best.torchscript imgsz=640 data=stars_constellations_dataset/constellation_data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Model saved to models/constellation_detector_yolov8s.pt\n",
      "Constellation detection model training and evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "DATASET_PATH = \"stars_constellations_dataset\"  # Path to dataset\n",
    "IMG_SIZE = 640  # Target image size\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0005\n",
    "MODEL_TYPE = \"yolov8s.pt\"  # Using the small variant (11.2M parameters)\n",
    "\n",
    "# Define constellation classes (16 classes as per requirements)\n",
    "CLASSES = [\n",
    "    \"Aquila\", \"Bootes\", \"Canis Major\", \"Canis Minor\", \"Cassiopeia\",\n",
    "    \"Cygnus\", \"Gemini\", \"Leo\", \"Lyra\", \"Moon\", \n",
    "    \"Orion\", \"Pleiades\", \"Sagittarius\", \"Taurus\", \"Ursa Major\", \"Moon\"\n",
    "]\n",
    "\n",
    "def create_dataset_structure():\n",
    "    \"\"\"\n",
    "    Create the necessary directory structure for YOLOv8 format\n",
    "    \"\"\"\n",
    "    os.makedirs(f\"{DATASET_PATH}/images/train\", exist_ok=True)\n",
    "    os.makedirs(f\"{DATASET_PATH}/images/val\", exist_ok=True)\n",
    "    os.makedirs(f\"{DATASET_PATH}/images/test\", exist_ok=True)\n",
    "    os.makedirs(f\"{DATASET_PATH}/labels/train\", exist_ok=True)\n",
    "    os.makedirs(f\"{DATASET_PATH}/labels/val\", exist_ok=True)\n",
    "    os.makedirs(f\"{DATASET_PATH}/labels/test\", exist_ok=True)\n",
    "    \n",
    "    return\n",
    "\n",
    "def preprocess_images(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Preprocess images by resizing to 640x640 as per requirements\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    image_files = [f for f in os.listdir(input_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    for img_file in tqdm(image_files, desc=\"Preprocessing images\"):\n",
    "        img_path = os.path.join(input_dir, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        # Check if image loaded correctly\n",
    "        if img is None:\n",
    "            print(f\"Failed to load image: {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Resize to square 640x640\n",
    "        img_resized = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        # Save the preprocessed image\n",
    "        output_path = os.path.join(output_dir, img_file)\n",
    "        cv2.imwrite(output_path, img_resized)\n",
    "    \n",
    "    return\n",
    "\n",
    "def split_dataset(image_list, labels_list, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Split dataset into train, validation and test sets based on specified ratio\n",
    "    \"\"\"\n",
    "    # First split into train and temporary sets\n",
    "    train_images, temp_images, train_labels, temp_labels = train_test_split(\n",
    "        image_list, labels_list, test_size=(val_ratio + test_ratio), random_state=42\n",
    "    )\n",
    "    \n",
    "    # Split temporary set into validation and test sets\n",
    "    val_ratio_adjusted = val_ratio / (val_ratio + test_ratio)\n",
    "    val_images, test_images, val_labels, test_labels = train_test_split(\n",
    "        temp_images, temp_labels, test_size=(1 - val_ratio_adjusted), random_state=42\n",
    "    )\n",
    "    \n",
    "    return (train_images, train_labels), (val_images, val_labels), (test_images, test_labels)\n",
    "\n",
    "def create_yaml_config():\n",
    "    \"\"\"\n",
    "    Create YAML configuration file for YOLOv8 training\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        'path': os.path.abspath(DATASET_PATH),\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'test': 'images/test',\n",
    "        'names': {i: name for i, name in enumerate(CLASSES)}\n",
    "    }\n",
    "    \n",
    "    with open(f\"{DATASET_PATH}/constellation_data.yaml\", 'w') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"Created YAML configuration at {DATASET_PATH}/constellation_data.yaml\")\n",
    "    return f\"{DATASET_PATH}/constellation_data.yaml\"\n",
    "\n",
    "def train_model(yaml_path):\n",
    "    \"\"\"\n",
    "    Train the YOLOv8s model using the dataset\n",
    "    \"\"\"\n",
    "    # Load a pretrained YOLOv8s model\n",
    "    model = YOLO(MODEL_TYPE)\n",
    "    \n",
    "    # Train the model\n",
    "    results = model.train(\n",
    "        data=yaml_path,\n",
    "        epochs=EPOCHS,\n",
    "        batch=BATCH_SIZE,\n",
    "        imgsz=IMG_SIZE,\n",
    "        optimizer=\"Adam\",  # As per requirements\n",
    "        lr0=LEARNING_RATE,  # Initial learning rate\n",
    "        conf=0.25,  # Detection confidence threshold\n",
    "        name=\"constellation_detector\",\n",
    "        device=0,  # Use your GPU\n",
    "        amp=False  # Disable Automatic Mixed Precision to avoid CUDA errors\n",
    "    )\n",
    "    \n",
    "    return model, results\n",
    "\n",
    "def evaluate_model(model):\n",
    "    \"\"\"\n",
    "    Evaluate model performance using mAP50 and other metrics\n",
    "    \"\"\"\n",
    "    # Validate the model (this will calculate mAP50 as specified in requirements)\n",
    "    results = model.val()\n",
    "    \n",
    "    # Safely convert metrics to float values\n",
    "    def safe_float_convert(value):\n",
    "        try:\n",
    "            if hasattr(value, 'item'):  # Handle tensor values\n",
    "                return value.item()\n",
    "            elif hasattr(value, '__len__') and len(value) == 1:  # Handle length-1 arrays\n",
    "                return float(value[0])\n",
    "            else:\n",
    "                return float(value)  # Try direct conversion\n",
    "        except (TypeError, ValueError, IndexError):\n",
    "            return 0.0  # Default value if conversion fails\n",
    "    \n",
    "    metrics = {\n",
    "        \"mAP50\": safe_float_convert(results.box.map50),\n",
    "        \"precision\": safe_float_convert(results.box.p),\n",
    "        \"recall\": safe_float_convert(results.box.r),\n",
    "        \"f1\": safe_float_convert(results.box.f1)\n",
    "    }\n",
    "    \n",
    "    print(\"\\nEvaluation Metrics:\")\n",
    "    print(f\"mAP50: {metrics['mAP50']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def detect_constellations(model, image_path):\n",
    "    \"\"\"\n",
    "    Perform constellation detection on a single image\n",
    "    \"\"\"\n",
    "    # Run inference\n",
    "    results = model.predict(image_path, conf=0.25)\n",
    "    \n",
    "    # Process results\n",
    "    result = results[0]\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(result.plot())\n",
    "    plt.axis('off')\n",
    "    plt.title('Constellation Detection')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detections\n",
    "    for box in result.boxes:\n",
    "        class_id = int(box.cls[0].item())\n",
    "        confidence = box.conf[0].item()\n",
    "        coordinates = box.xyxy[0].tolist()\n",
    "        print(f\"Detected {CLASSES[class_id]} with confidence {confidence:.2f} at {coordinates}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    # Step 1: Create dataset structure\n",
    "    create_dataset_structure()\n",
    "    \n",
    "    # Note: At this point you would need to:\n",
    "    # 1. Collect/prepare your 1,750 labeled constellation images\n",
    "    # 2. Convert annotations to YOLO format\n",
    "    # 3. Place images and labels in the appropriate directories\n",
    "    print(\"Please prepare your dataset by placing images and labels in the appropriate directories\")\n",
    "    \n",
    "    # Step 2: Create YAML configuration\n",
    "    yaml_path = create_yaml_config()\n",
    "    \n",
    "    # Step 3: Train the model\n",
    "    print(\"Training YOLOv8s model...\")\n",
    "    model, training_results = train_model(yaml_path)\n",
    "    \n",
    "    # Step 4: Evaluate the model\n",
    "    print(\"Evaluating model performance...\")\n",
    "    metrics = evaluate_model(model)\n",
    "    \n",
    "    # Save the trained model\n",
    "    model_save_path = \"models/constellation_detector_yolov8s.pt\"\n",
    "    os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "    model.export(format=\"torchscript\")  # Export to PyTorch format\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "    \n",
    "    # For demonstration, you would use your own test image\n",
    "    # detect_constellations(model, \"path_to_test_image.jpg\")\n",
    "    \n",
    "    print(\"Constellation detection model training and evaluation complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constellation Detection Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "MODEL_PATH = \"models/constellation_detector_yolov8s.pt\"  # Path to trained model\n",
    "TEST_DATA_PATH = \"stars_constellations_dataset/images/test\"  # Path to test images\n",
    "CONF_THRESHOLD = 0.25  # Confidence threshold for detection\n",
    "IOU_THRESHOLD = 0.5  # IoU threshold for NMS\n",
    "\n",
    "# Constellation classes (16 classes)\n",
    "CLASSES = [\n",
    "    \"Aquila\", \"Bootes\", \"Canis Major\", \"Canis Minor\", \"Cassiopeia\",\n",
    "    \"Cygnus\", \"Gemini\", \"Leo\", \"Lyra\", \"Moon\", \n",
    "    \"Orion\", \"Pleiades\", \"Sagittarius\", \"Taurus\", \"Ursa Major\", \"Moon\"\n",
    "]\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load the trained YOLOv8s model\"\"\"\n",
    "    try:\n",
    "        model = YOLO(MODEL_PATH)\n",
    "        print(f\"Model loaded successfully from {MODEL_PATH}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "def evaluate_on_test_set(model):\n",
    "    \"\"\"Evaluate the model on the test dataset\"\"\"\n",
    "    if model is None:\n",
    "        print(\"Model not loaded. Cannot evaluate.\")\n",
    "        return\n",
    "    \n",
    "    results = model.val(data=f\"{os.path.dirname(TEST_DATA_PATH)}/data.yaml\")\n",
    "    \n",
    "    # Extract metrics\n",
    "    metrics = {\n",
    "        \"mAP50\": results.box.map50,  # Primary metric\n",
    "        \"precision\": results.box.p,   # Secondary metric\n",
    "        \"recall\": results.box.r,      # Secondary metric\n",
    "        \"f1\": results.box.f1          # Secondary metric (F1 Score)\n",
    "    }\n",
    "    \n",
    "    # Display metrics\n",
    "    print(\"\\nEvaluation Metrics:\")\n",
    "    print(f\"mAP50: {metrics['mAP50']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def visualize_results(model, num_samples=5):\n",
    "    \"\"\"Visualize detection results on random test samples\"\"\"\n",
    "    if model is None:\n",
    "        print(\"Model not loaded. Cannot visualize.\")\n",
    "        return\n",
    "    \n",
    "    # Get test images\n",
    "    test_images = [os.path.join(TEST_DATA_PATH, f) for f in os.listdir(TEST_DATA_PATH) \n",
    "                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    if len(test_images) == 0:\n",
    "        print(\"No test images found.\")\n",
    "        return\n",
    "    \n",
    "    # Select random samples\n",
    "    if len(test_images) > num_samples:\n",
    "        test_samples = np.random.choice(test_images, num_samples, replace=False)\n",
    "    else:\n",
    "        test_samples = test_images\n",
    "    \n",
    "    # Create figure for visualization\n",
    "    fig, axes = plt.subplots(1, len(test_samples), figsize=(20, 4))\n",
    "    if len(test_samples) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Process each sample\n",
    "    for i, img_path in enumerate(test_samples):\n",
    "        # Run inference\n",
    "        results = model.predict(img_path, conf=CONF_THRESHOLD, iou=IOU_THRESHOLD)\n",
    "        result = results[0]\n",
    "        \n",
    "        # Get the original image for display\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Plot result\n",
    "        result_img = result.plot()\n",
    "        axes[i].imshow(result_img)\n",
    "        axes[i].set_title(f\"Sample {i+1}\")\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "        # Print detections\n",
    "        detections = []\n",
    "        for box in result.boxes:\n",
    "            class_id = int(box.cls[0].item())\n",
    "            confidence = box.conf[0].item()\n",
    "            detections.append(f\"{CLASSES[class_id]}: {confidence:.2f}\")\n",
    "        \n",
    "        print(f\"Sample {i+1} detections:\", \", \".join(detections))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"constellation_detection_samples.png\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(model):\n",
    "    \"\"\"Plot confusion matrix for classification results\"\"\"\n",
    "    if model is None:\n",
    "        print(\"Model not loaded. Cannot plot confusion matrix.\")\n",
    "        return\n",
    "    \n",
    "    # Get all test images\n",
    "    test_images = [os.path.join(TEST_DATA_PATH, f) for f in os.listdir(TEST_DATA_PATH) \n",
    "                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    # Get ground truth labels from file names or label files\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    for img_path in test_images:\n",
    "        # Get ground truth class (assuming filename contains class info)\n",
    "        # In real scenario, you would read this from label files\n",
    "        img_name = os.path.basename(img_path)\n",
    "        label_path = img_path.replace('images', 'labels').replace('.jpg', '.txt').replace('.png', '.txt')\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                line = f.readline().strip()\n",
    "                if line:\n",
    "                    class_id = int(line.split(' ')[0])\n",
    "                    true_labels.append(class_id)\n",
    "                else:\n",
    "                    continue\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # Run inference\n",
    "        results = model.predict(img_path, conf=CONF_THRESHOLD)\n",
    "        result = results[0]\n",
    "        \n",
    "        # Get highest confidence detection\n",
    "        if len(result.boxes) > 0:\n",
    "            # Find detection with highest confidence\n",
    "            confidences = [box.conf[0].item() for box in result.boxes]\n",
    "            max_conf_idx = np.argmax(confidences)\n",
    "            pred_class_id = int(result.boxes[max_conf_idx].cls[0].item())\n",
    "            pred_labels.append(pred_class_id)\n",
    "        else:\n",
    "            # No detection, skip this image\n",
    "            true_labels.pop()  # Remove the corresponding true label\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    if len(true_labels) > 0 and len(pred_labels) > 0:\n",
    "        cm = confusion_matrix(true_labels, pred_labels, labels=range(len(CLASSES)))\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title('Confusion Matrix for Constellation Detection')\n",
    "        plt.savefig(\"confusion_matrix.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Classification report\n",
    "        report = classification_report(true_labels, pred_labels, target_names=CLASSES)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(report)\n",
    "    else:\n",
    "        print(\"Not enough data to create confusion matrix.\")\n",
    "\n",
    "def visualize_loss_curves():\n",
    "    \"\"\"Visualize training loss curves from the results file\"\"\"\n",
    "    try:\n",
    "        # Location of results CSV (this path might vary based on your training output)\n",
    "        results_path = \"runs/detect/constellation_detector/results.csv\"\n",
    "        \n",
    "        if not os.path.exists(results_path):\n",
    "            print(f\"Results file not found at {results_path}\")\n",
    "            return\n",
    "        \n",
    "        # Load results\n",
    "        results = pd.read_csv(results_path)\n",
    "        \n",
    "        # Plot loss curves\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Plot box loss\n",
    "        plt.subplot(3, 1, 1)\n",
    "        plt.plot(results['epoch'], results['box_loss'], label='Box Loss', color='blue')\n",
    "        plt.title('Box Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot classification loss\n",
    "        plt.subplot(3, 1, 2)\n",
    "        plt.plot(results['epoch'], results['cls_loss'], label='Classification Loss', color='green')\n",
    "        plt.title('Classification Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot distribution focal loss (DFL)\n",
    "        plt.subplot(3, 1, 3)\n",
    "        plt.plot(results['epoch'], results['dfl_loss'], label='Distribution Focal Loss', color='red')\n",
    "        plt.title('Distribution Focal Loss (DFL)')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"training_loss_curves.png\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting loss curves: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Step 1: Load model\n",
    "    model = load_model()\n",
    "    \n",
    "    # Step 2: Evaluate on test set\n",
    "    metrics = evaluate_on_test_set(model)\n",
    "    \n",
    "    # Step 3: Visualize results on sample images\n",
    "    visualize_results(model, num_samples=5)\n",
    "    \n",
    "    # Step 4: Plot confusion matrix\n",
    "    plot_confusion_matrix(model)\n",
    "    \n",
    "    # Step 5: Visualize loss curves\n",
    "    visualize_loss_curves()\n",
    "    \n",
    "    print(\"Evaluation complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constellation Detection Inference Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "MODEL_PATH = \"models/constellation_detector_yolov8s.pt\"  # Path to trained model\n",
    "CONF_THRESHOLD = 0.25  # Confidence threshold for detection\n",
    "IOU_THRESHOLD = 0.5    # IoU threshold for non-maximum suppression\n",
    "CLASSES = [\n",
    "    \"Aquila\", \"Bootes\", \"Canis Major\", \"Canis Minor\", \"Cassiopeia\",\n",
    "    \"Cygnus\", \"Gemini\", \"Leo\", \"Lyra\", \"Moon\", \n",
    "    \"Orion\", \"Pleiades\", \"Sagittarius\", \"Taurus\", \"Ursa Major\", \"Moon\"\n",
    "]\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load the YOLOv8s model for inference\"\"\"\n",
    "    try:\n",
    "        model = YOLO(MODEL_PATH)\n",
    "        print(f\"Model loaded successfully from {MODEL_PATH}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_image(model, image_path):\n",
    "    \"\"\"Process a single image and display results\"\"\"\n",
    "    if model is None:\n",
    "        print(\"Model not loaded. Cannot process image.\")\n",
    "        return None\n",
    "    \n",
    "    # Load image\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Failed to load image: {image_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Convert to RGB for display\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Run inference\n",
    "        start_time = time.time()\n",
    "        results = model.predict(image_path, conf=CONF_THRESHOLD, iou=IOU_THRESHOLD)\n",
    "        inference_time = time.time() - start_time\n",
    "        \n",
    "        result = results[0]\n",
    "        \n",
    "        # Create result image\n",
    "        result_img = result.plot()\n",
    "        \n",
    "        # Print detection information\n",
    "        print(f\"\\nProcessed image: {image_path}\")\n",
    "        print(f\"Inference time: {inference_time:.4f} seconds\")\n",
    "        print(\"Detections:\")\n",
    "        \n",
    "        for i, box in enumerate(result.boxes):\n",
    "            class_id = int(box.cls[0].item())\n",
    "            confidence = box.conf[0].item()\n",
    "            coordinates = box.xyxy[0].tolist()  # x1, y1, x2, y2 format\n",
    "            \n",
    "            print(f\"  {i+1}. {CLASSES[class_id]}: {confidence:.4f} at {[round(c, 2) for c in coordinates]}\")\n",
    "        \n",
    "        return result_img\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_directory(model, directory_path, output_dir=\"output\"):\n",
    "    \"\"\"Process all images in a directory and save results\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing cuda installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "GPU device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda if torch.cuda.is_available() else 'N/A'}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "constellation_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
